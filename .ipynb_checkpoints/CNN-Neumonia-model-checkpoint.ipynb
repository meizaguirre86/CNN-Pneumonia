{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dn-6c02VmqiN"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many photos we have to train, test and validate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zvSODo0f9LaU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1341\n",
      "8\n",
      "234\n",
      "3875\n",
      "8\n",
      "390\n"
     ]
    }
   ],
   "source": [
    "train_folder= r\"C:\\Users\\meiza\\Documents\\GitHub\\CNN-Pneumonia\\chest_xray\\train\"\n",
    "val_folder = r\"C:\\Users\\meiza\\Documents\\GitHub\\CNN-Pneumonia\\chest_xray\\val\"\n",
    "test_folder = r\"C:\\Users\\meiza\\Documents\\GitHub\\CNN-Pneumonia\\chest_xray\\test\"\n",
    "\n",
    "train_normal_folder= r\"C:\\Users\\meiza\\Documents\\GitHub\\CNN-Pneumonia\\chest_xray\\train\\NORMAL\"\n",
    "val_normal_folder = r\"C:\\Users\\meiza\\Documents\\GitHub\\CNN-Pneumonia\\chest_xray\\val\\NORMAL\"\n",
    "test_normal_folder = r\"C:\\Users\\meiza\\Documents\\GitHub\\CNN-Pneumonia\\chest_xray\\test\\NORMAL\"\n",
    "\n",
    "train_pneumonia_folder= r\"C:\\Users\\meiza\\Documents\\GitHub\\CNN-Pneumonia\\chest_xray\\train\\PNEUMONIA\"\n",
    "val_pneumonia_folder = r\"C:\\Users\\meiza\\Documents\\GitHub\\CNN-Pneumonia\\chest_xray\\val\\PNEUMONIA\"\n",
    "test_pneumonia_folder = r\"C:\\Users\\meiza\\Documents\\GitHub\\CNN-Pneumonia\\chest_xray\\test\\PNEUMONIA\"\n",
    "\n",
    "print(len(os.listdir(train_normal_folder)))\n",
    "print(len(os.listdir(val_normal_folder)))\n",
    "print(len(os.listdir(test_normal_folder)))\n",
    "print(len(os.listdir(train_pneumonia_folder)))\n",
    "print(len(os.listdir(val_pneumonia_folder)))\n",
    "print(len(os.listdir(test_pneumonia_folder)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the model composed of convolution, max pooling, flatten, and dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-BQrav4anTmj"
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step consists in generating and transforming our dataset to fit it to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fQrZfVgz4j2g"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "                                    rescale=1/255,featurewise_center=False,\n",
    "                                    samplewise_center=False,\n",
    "                                    featurewise_std_normalization=False,\n",
    "                                    samplewise_std_normalization=False,\n",
    "                                    zca_whitening=False,\n",
    "                                    rotation_range = 30,\n",
    "                                    zoom_range = 0.2,\n",
    "                                    width_shift_range=0.1,\n",
    "                                    height_shift_range=0.1,\n",
    "                                    horizontal_flip = False,\n",
    "                                    vertical_flip=False)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                                                    train_folder,\n",
    "                                                    target_size=(150, 150),\n",
    "                                                    batch_size=32,\n",
    "                                                    class_mode='categorical')\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "                                                    val_folder,\n",
    "                                                    target_size=(150, 150),\n",
    "                                                    batch_size=32,\n",
    "                                                    class_mode='categorical')\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "                                                    test_folder,\n",
    "                                                    target_size=(150, 150),\n",
    "                                                    batch_size=32,\n",
    "                                                    class_mode='categorical')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5qE1G6JB4fMn",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "163/163 [==============================] - 129s 790ms/step - loss: 0.4067 - accuracy: 0.8181 - val_loss: 0.5215 - val_accuracy: 0.8125\n",
      "Epoch 2/4\n",
      "163/163 [==============================] - 115s 703ms/step - loss: 0.2386 - accuracy: 0.9005 - val_loss: 0.6898 - val_accuracy: 0.6875\n",
      "Epoch 3/4\n",
      "163/163 [==============================] - 120s 738ms/step - loss: 0.2230 - accuracy: 0.9101 - val_loss: 0.4376 - val_accuracy: 0.9375\n",
      "Epoch 4/4\n",
      "163/163 [==============================] - 135s 831ms/step - loss: 0.1841 - accuracy: 0.9287 - val_loss: 0.6788 - val_accuracy: 0.6875\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                              epochs=10,\n",
    "                              verbose=1,\n",
    "                              validation_data=val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the following graphs. We can see that the more epochs we run the more accuracy we achieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MWZrJN4-65RC"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-221768a5e31c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0macc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.image  as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc=history.history['accuracy']\n",
    "val_acc=history.history['val_accuracy']\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs=range(len(acc)) # Get number of epochs\n",
    "\n",
    "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
    "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
    "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to calculate the accuracy with test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 8s 389ms/step - loss: 0.2456 - accuracy: 0.9167\n",
      "Loss of the model is -  24.557198584079742 %\n",
      "20/20 [==============================] - 7s 349ms/step - loss: 0.2456 - accuracy: 0.9167\n",
      "Accuracy of the model is -  91.66666865348816 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss of the model is - \" , model.evaluate(test_generator)[0]*100 , \"%\")\n",
    "print(\"Accuracy of the model is - \" , model.evaluate(test_generator)[1]*100 , \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally and once we get our expected model, we save it to avoid having to train again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Exercise 6 - Answer.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
